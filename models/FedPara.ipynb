{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3330,
     "status": "ok",
     "timestamp": 1666623084334,
     "user": {
      "displayName": "Hyeon Woo Nam",
      "userId": "08572911294116377288"
     },
     "user_tz": -540
    },
    "id": "hgHq3UpPeOqy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1666625920319,
     "user": {
      "displayName": "Hyeon Woo Nam",
      "userId": "08572911294116377288"
     },
     "user_tz": -540
    },
    "id": "WytOsCJ7eelG"
   },
   "outputs": [],
   "source": [
    "class LowRank(nn.Module):\n",
    "  def __init__(self,\n",
    "               in_channels: int,\n",
    "               out_channels: int,\n",
    "               low_rank: int,\n",
    "               kernel_size: int):\n",
    "    super().__init__()\n",
    "    self.T = nn.Parameter(\n",
    "        torch.empty(size=(low_rank, low_rank, kernel_size, kernel_size)),\n",
    "        requires_grad=True\n",
    "    )\n",
    "    self.O = nn.Parameter(\n",
    "        torch.empty(size=(low_rank, out_channels)),\n",
    "        requires_grad=True\n",
    "    )\n",
    "    self.I = nn.Parameter(\n",
    "        torch.empty(size=(low_rank, in_channels)),\n",
    "        requires_grad=True\n",
    "    )\n",
    "    self._init_parameters()\n",
    "  \n",
    "  def _init_parameters(self):\n",
    "    # Initialization affects the convergence stability for our parameterization\n",
    "    fan = nn.init._calculate_correct_fan(self.T, mode='fan_in')\n",
    "    gain = nn.init.calculate_gain('relu', 0)\n",
    "    std_t = gain / np.sqrt(fan)\n",
    "\n",
    "    fan = nn.init._calculate_correct_fan(self.O, mode='fan_in')\n",
    "    std_o = gain / np.sqrt(fan)\n",
    "\n",
    "    fan = nn.init._calculate_correct_fan(self.I, mode='fan_in')\n",
    "    std_i = gain / np.sqrt(fan)\n",
    "\n",
    "    nn.init.normal_(self.T, 0, std_t)\n",
    "    nn.init.normal_(self.O, 0, std_o)\n",
    "    nn.init.normal_(self.I, 0, std_i)\n",
    "\n",
    "  def forward(self):\n",
    "    # torch.einsum simplify the tensor produce (matrix multiplication)\n",
    "    return torch.einsum(\"xyzw,xo,yi->oizw\", self.T, self.O, self.I)\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "  def __init__(self,\n",
    "               in_channels: int,\n",
    "               out_channels: int,\n",
    "               kernel_size: int=3,\n",
    "               stride: int=1,\n",
    "               padding: int=0,\n",
    "               bias: bool=False,\n",
    "               ratio: float=0.0):\n",
    "    super().__init__()\n",
    "    self.in_channels = in_channels\n",
    "    self.out_channels = out_channels\n",
    "    self.kernel_size = kernel_size\n",
    "    self.stride = stride\n",
    "    self.padding = padding\n",
    "    self.bias = bias\n",
    "    self.ratio = ratio\n",
    "    self.low_rank = self._calc_from_ratio()\n",
    "\n",
    "    self.W1 = LowRank(in_channels, out_channels, self.low_rank, kernel_size)\n",
    "    self.W2 = LowRank(in_channels, out_channels, self.low_rank, kernel_size)\n",
    "    self.bias = nn.Parameter(torch.zeros(out_channels)) if bias else None\n",
    "\n",
    "  def _calc_from_ratio(self):\n",
    "    # Return the low-rank of sub-matrices given the compression ratio \n",
    "    r1 = int(np.ceil(np.sqrt(self.out_channels)))\n",
    "    r2 = int(np.ceil(np.sqrt(self.in_channels)))\n",
    "    r = np.max((r1, r2))\n",
    "\n",
    "    num_target_params = self.out_channels * self.in_channels * \\\n",
    "      (self.kernel_size ** 2) * self.ratio\n",
    "    r3 = np.sqrt(\n",
    "        ((self.out_channels + self.in_channels) ** 2) / (4 *(self.kernel_size ** 4)) + \\\n",
    "        num_target_params / (2 * (self.kernel_size ** 2))\n",
    "    ) - (self.out_channels + self.in_channels) / (2 * (self.kernel_size ** 2))\n",
    "    r3 = int(np.ceil(r3))\n",
    "    r = np.max((r, r3))\n",
    "\n",
    "    return r\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Hadamard product of two submatrices\n",
    "    W = self.W1() * self.W2()\n",
    "    out = F.conv2d(input=x, weight=W, bias=self.bias,\n",
    "                 stride=self.stride, padding=self.padding)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gp5Z6vVofxo"
   },
   "source": [
    "Adjusting the number of parameters given compression ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1666625920980,
     "user": {
      "displayName": "Hyeon Woo Nam",
      "userId": "08572911294116377288"
     },
     "user_tz": -540
    },
    "id": "9_j-ihPAlLl8",
    "outputId": "222b59e3-9c9f-4c81-8f04-0ab5f600ade2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589824 60192 0.10205078125\n",
      "589824 178050 0.3018697102864583\n",
      "589824 296434 0.5025804307725694\n",
      "589824 414792 0.7032470703125\n",
      "589824 533192 0.9039849175347222\n"
     ]
    }
   ],
   "source": [
    "orig_num_params = 256 * 256 * 3 * 3\n",
    "\n",
    "layer1 = Conv2d(256, 256, 3, 1, 1, False, 0.1)\n",
    "layer3 = Conv2d(256, 256, 3, 1, 1, False, 0.3)\n",
    "layer5 = Conv2d(256, 256, 3, 1, 1, False, 0.5)\n",
    "layer7 = Conv2d(256, 256, 3, 1, 1, False, 0.7)\n",
    "layer9 = Conv2d(256, 256, 3, 1, 1, False, 0.9)\n",
    "\n",
    "num1 = sum(p.numel() for p in layer1.parameters() if p.requires_grad)\n",
    "num3 = sum(p.numel() for p in layer3.parameters() if p.requires_grad)\n",
    "num5 = sum(p.numel() for p in layer5.parameters() if p.requires_grad)\n",
    "num7 = sum(p.numel() for p in layer7.parameters() if p.requires_grad)\n",
    "num9 = sum(p.numel() for p in layer9.parameters() if p.requires_grad)\n",
    "\n",
    "print(orig_num_params, num1, num1 / orig_num_params)\n",
    "print(orig_num_params, num3, num3 / orig_num_params)\n",
    "print(orig_num_params, num5, num5 / orig_num_params)\n",
    "print(orig_num_params, num7, num7 / orig_num_params)\n",
    "print(orig_num_params, num9, num9 / orig_num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2-Hl-YLopTF"
   },
   "source": [
    "Feedforward test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1666625930725,
     "user": {
      "displayName": "Hyeon Woo Nam",
      "userId": "08572911294116377288"
     },
     "user_tz": -540
    },
    "id": "YQZ7VfdqmXRh",
    "outputId": "7fbbe58b-3028-4989-acd7-2432082fd202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 256, 16, 16])\n",
      "torch.Size([1, 128, 16, 16])\n",
      "torch.Size([1, 128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=(1, 128, 16, 16))\n",
    "layer = Conv2d(128, 256, 3, 1, 1, False, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn(size=(1, 128, 16, 16))\n",
    "layer = Conv2d(128, 256, 3, 1, 1, True, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn(size=(1, 128, 16, 16))\n",
    "layer = Conv2d(128, 128, 3, 1, 1, False, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn(size=(1, 128, 16, 16))\n",
    "layer = Conv2d(128, 128, 3, 1, 1, True, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l1aZg1Eknxki"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 16, 16])\n",
      "torch.Size([256, 16, 16])\n",
      "torch.Size([128, 16, 16])\n",
      "torch.Size([128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(size=( 128, 16, 16))\n",
    "layer = Conv2d(128, 256, 3, 1, 1, False, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn(size=(128, 16, 16))\n",
    "layer = Conv2d(128, 256, 3, 1, 1, True, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn(size=( 128, 16, 16))\n",
    "layer = Conv2d(128, 128, 3, 1, 1, False, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "\n",
    "x = torch.randn(size=( 128, 16, 16))\n",
    "layer = Conv2d(128, 128, 3, 1, 1, True, 0.1)\n",
    "out = layer(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'generator' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m layer7 \u001b[38;5;241m=\u001b[39m Conv2d(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m      7\u001b[0m layer9 \u001b[38;5;241m=\u001b[39m Conv2d(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      9\u001b[0m num1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m layer1\u001b[38;5;241m.\u001b[39mparameters() )\n\u001b[1;32m     10\u001b[0m num3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m layer3\u001b[38;5;241m.\u001b[39mparameters() )\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'generator' has no len()"
     ]
    }
   ],
   "source": [
    "orig_num_params = 256 * 256 * 3 * 3\n",
    "\n",
    "layer1 = Conv2d(256, 256, 3, 1, 1, False, 0.1)\n",
    "layer3 = Conv2d(256, 256, 3, 1, 1, False, 0.3)\n",
    "layer5 = Conv2d(256, 256, 3, 1, 1, False, 0.5)\n",
    "layer7 = Conv2d(256, 256, 3, 1, 1, False, 0.7)\n",
    "layer9 = Conv2d(256, 256, 3, 1, 1, False, 0.9)\n",
    "num1 = sum(p.numel() for p in layer1.parameters() )\n",
    "num3 = sum(p.numel() for p in layer3.parameters() )\n",
    "num5 = sum(p.numel() for p in layer5.parameters() )\n",
    "num7 = sum(p.numel() for p in layer7.parameters() )\n",
    "num9 = sum(p.numel() for p in layer9.parameters() )\n",
    "\n",
    "print(orig_num_params, num1, num1 / orig_num_params)\n",
    "print(orig_num_params, num3, num3 / orig_num_params)\n",
    "print(orig_num_params, num5, num5 / orig_num_params)\n",
    "print(orig_num_params, num7, num7 / orig_num_params)\n",
    "print(orig_num_params, num9, num9 / orig_num_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNr8AHV6ITSYUeSzt8PTYfQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GPU_X",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
